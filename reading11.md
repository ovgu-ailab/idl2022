---
layout: default
title: Reading Assignment
id: reading11
---


# Reading Assignment: Introspection
[The blog about tf-explain](https://www.sicara.ai/blog/2019-08-28-interpretability-deep-learning-tensorflow) gives a nice overview about different introspection techniques. (it's not very comprehensive though)
The toolbox works with TF 2.0, but currently only works on image data.

[This overview blog post](https://distill.pub/2017/feature-visualization/)
and a [more recent addition](https://distill.pub/2018/building-blocks/) will give you a nice overview about feature visualization.

Now it's time to look at some specific techniques. Dig as deep as you like! These websites (and papers) provide plenty of background information.

1. [Deepvis](http://yosinski.com/deepvis)
	(code and paper are linked)

2. [LSTMVis](http://lstm.seas.harvard.edu/)
	(code and paper are linked)

3. [exBert - Visual Analysis of Transformer Models](https://exbert.net) (code and paper are linked)

4. [Heatmapping](http://heatmapping.org/) - especially [Methods for Interpreting and Understanding Deep Neural Networks (2017), Montavon et al.](https://arxiv.org/abs/1706.07979)

5. [GradCAM](http://gradcam.cloudcv.org/) Gradient-weighted Class Activation Mapping

Bonus:
- For those who are interested in the beginnings of this field of research: [Deep Inside Convolutional Networks](https://arxiv.org/pdf/1312.6034.pdf)
- [Linear Classifier Probes](https://arxiv.org/pdf/1610.01644.pdf)
