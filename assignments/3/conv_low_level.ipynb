{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "conv_low_level.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXRyS-rkCLys"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubiHwa2oCLy0"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_labels[0])\n",
        "plt.imshow(train_images[0], cmap=\"Greys_r\")\n",
        "\n",
        "# first difference: data is not reshaped to 784 anymore, but 28x28x1\n",
        "# note the 1 color channel!! this is important\n",
        "train_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
        "train_data = train_data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "\n",
        "test_images = test_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255\n",
        "test_labels = test_labels.astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCArVlC-CLy3"
      },
      "source": [
        "train_steps = 1000  # might need more steps\n",
        "\n",
        "# convolutional kernels/biases\n",
        "W_conv1 = tf.Variable(tf.random.uniform([5, 5, 1, 16], -0.1, 0.1))\n",
        "b_conv1 = tf.Variable(tf.zeros([16]))\n",
        "W_conv2 = tf.Variable(tf.random.uniform([5, 5, 16, 32], -0.1, 0.1))\n",
        "b_conv2 = tf.Variable(tf.zeros([32]))\n",
        "\n",
        "# fully connected layer at the end\n",
        "W_out = tf.Variable(tf.random.uniform([7*7*32, 10]))\n",
        "b_out = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "variables = [W_conv1, b_conv1, W_conv2, b_conv2, W_out, b_out]\n",
        "\n",
        "\n",
        "# 2 conv layers, each followed by 2x2 max pool\n",
        "# you should look up the parameters in the API!\n",
        "def model(inputs):\n",
        "    conv1 = tf.nn.relu(tf.nn.conv2d(inputs, W_conv1, 1, padding=\"SAME\") + b_conv1)\n",
        "    conv1 = tf.nn.max_pool2d(conv1, 2, 2, padding=\"SAME\")\n",
        "    conv2 = tf.nn.relu(tf.nn.conv2d(conv1, W_conv2, 1, padding=\"SAME\") + b_conv2)\n",
        "    conv2 = tf.nn.max_pool2d(conv2, 2, 2, padding=\"SAME\")\n",
        "    conv2 = tf.reshape(conv2, [-1, 7*7*32])  # \"flatten\"\n",
        "\n",
        "    logits = tf.matmul(conv2, W_out) + b_out\n",
        "\n",
        "    return logits\n",
        "\n",
        "\n",
        "# Adam makes things much smoother\n",
        "optimizer = tf.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8oHQ6-JCLy4"
      },
      "source": [
        "# this basically hasn't changed\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "      \n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    \n",
        "    if not step % 100:\n",
        "        predictions = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, label_batch),\n",
        "                             tf.float32))\n",
        "        print(\"Step {} Loss: {} Accuracy: {}\".format(step, loss, accuracy))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u5M_Nv0CLy7"
      },
      "source": [
        "# evaluating the full test set at once should be ok on colab, but might be too much for your local machine!\n",
        "test_predictions = tf.argmax(model(test_images), axis=1,\n",
        "                       output_type=tf.int32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(test_predictions, test_labels),\n",
        "                             tf.float32))\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L3xWhMZCLy9"
      },
      "source": [
        "# here's an example of what a custom conv implementation might look like\n",
        "# it's in numpy because TF doesn't allow for assigning values to tensor indices.\n",
        "# a TF solution would be possible in other ways, but be more difficult to understand\n",
        "\n",
        "# this is the full version with batched inputs, multiple input and output channels\n",
        "# further below you can find simpler versions as well\n",
        "\n",
        "def custom_conv2d(inputs, filters):\n",
        "    # inputs: shape batch x height x width x in_channels\n",
        "    # filters: shape filter_width x filter_height x in_channels x out_channels\n",
        "    filter_height = filters.shape[0]\n",
        "    filter_width = filters.shape[1]\n",
        "    # output loses size since we do not use padding. (reduced by filter_size - 1)\n",
        "    output = np.zeros((inputs.shape[0], inputs.shape[1]-filter_height+1, inputs.shape[2]-filter_width+1, filters.shape[3]))\n",
        "\n",
        "    # loop for \"sliding the filter\"\n",
        "    for row_ind in range(output.shape[1]):\n",
        "        for col_ind in range(output.shape[2]):\n",
        "            # grab the respective part of the input\n",
        "            input_slice = inputs[:, row_ind:(row_ind + filter_height), col_ind:(col_ind + filter_width), :]\n",
        "            # b x h x w x i   *   h x w x i x o    ->    b x o\n",
        "            # element-wise product, but add axis to input so it's replicated over the output channel axis\n",
        "            local_product = input_slice[..., np.newaxis] * filters\n",
        "            # sum over width, height, input channels\n",
        "            local_reduce = np.sum(local_product, axis=(1, 2, 3))\n",
        "            #local_reduce = tf.einsum(\"bhwi,hwio -> bo\", input_slice, filters)  # alternative to the two lines above\n",
        "            output[:, row_ind, col_ind, :] = local_reduce\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEGsXbPzIm1-"
      },
      "source": [
        "# compare our implementation to the TF op\n",
        "dummy_images = np.random.normal(size=(16, 32, 32, 3))\n",
        "filters = np.random.normal(size=(5, 5, 3, 8))\n",
        "\n",
        "own_try = custom_conv2d(dummy_images, filters)\n",
        "tf_try = tf.nn.conv2d(dummy_images, filters, 1, padding=\"VALID\")\n",
        "\n",
        "tf_try.shape, own_try.shape  # shapes are the same?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN_XVq_rKE4b"
      },
      "source": [
        "# discrepancy should be very small (only due to numerics)\n",
        "np.max(abs(tf_try - own_try))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n60xF7kbKNcP"
      },
      "source": [
        "# some simpler versions...\n",
        "\n",
        "\n",
        "# most basic: inputs are 2d, filters as well. so single input/output channel\n",
        "def custom_conv2d_1(inputs, filters):\n",
        "    # inputs: height x width\n",
        "    # filters: f_h x f_w\n",
        "    filter_height = filters.shape[0]\n",
        "    filter_width = filters.shape[1]\n",
        "    output = np.zeros((inputs.shape[0]-filter_height+1, inputs.shape[1]-filter_width+1))\n",
        "\n",
        "    for row_ind in range(output.shape[0]):\n",
        "        for col_ind in range(output.shape[1]):\n",
        "            input_slice = inputs[row_ind:(row_ind + filter_height), col_ind:(col_ind + filter_width)]\n",
        "            # h x w   *   h x w -> 1\n",
        "            local_product = input_slice * filters\n",
        "            local_reduce = np.sum(local_product)\n",
        "            output[row_ind, col_ind] = local_reduce\n",
        "    return output\n",
        "\n",
        "\n",
        "# now we have inputs with multiple channels\n",
        "def custom_conv2d_2(inputs, filters):\n",
        "    # inputs: height x width x i\n",
        "    # filters: f_h x f_w x i\n",
        "    filter_height = filters.shape[0]\n",
        "    filter_width = filters.shape[1]\n",
        "    output = np.zeros((inputs.shape[0]-filter_height+1, inputs.shape[1]-filter_width+1))\n",
        "\n",
        "    for row_ind in range(output.shape[0]):\n",
        "        for col_ind in range(output.shape[1]):\n",
        "            input_slice = inputs[row_ind:(row_ind + filter_height), col_ind:(col_ind + filter_width), :]\n",
        "            # h x w x i   *   h x w x i -> 1\n",
        "            local_product = input_slice * filters\n",
        "            local_reduce = np.sum(local_product)\n",
        "            # note that there is still just a single output, even though there are multiple input channels\n",
        "            # the dot product summarizes over all input channels AND spatial dimensions\n",
        "            output[row_ind, col_ind] = local_reduce\n",
        "    return output\n",
        "\n",
        "\n",
        "# and finally, multiple output channels as well.\n",
        "# the full version above only adds a batch axis in the beginning\n",
        "def custom_conv2d_3(inputs, filters):\n",
        "    # inputs: height x width x i\n",
        "    # filters: f_h x f_w x i x o\n",
        "    filter_height = filters.shape[0]\n",
        "    filter_width = filters.shape[1]\n",
        "    output = np.zeros((inputs.shape[0]-filter_height+1, inputs.shape[1]-filter_width+1, filters.shape[3]))\n",
        "\n",
        "    for row_ind in range(output.shape[0]):\n",
        "        for col_ind in range(output.shape[1]):\n",
        "            input_slice = inputs[row_ind:(row_ind + filter_height), col_ind:(col_ind + filter_width), :]\n",
        "            # h x w x i   *   h x w x i x o -> o\n",
        "            # now we no longer want a single output, but one output per output channel (or \"filter\")\n",
        "            local_product = input_slice[..., np.newaxis] * filters\n",
        "            local_reduce = np.sum(local_product, axis=(0, 1, 2))\n",
        "            output[row_ind, col_ind] = local_reduce\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btZORQ0R8brY"
      },
      "source": [
        "# sanity check. we can trust multiplication and adding to work well\n",
        "# so we only check the shapes\n",
        "dummy_images = np.random.normal(size=(32, 32))\n",
        "filters = np.random.normal(size=(5, 5))\n",
        "\n",
        "# output shape reduced by 5-1, okay!\n",
        "custom_conv2d_1(dummy_images, filters).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R1pH26F8na6"
      },
      "source": [
        "# now add input channels\n",
        "dummy_images = np.random.normal(size=(32, 32, 3))\n",
        "filters = np.random.normal(size=(5, 5, 3))\n",
        "\n",
        "# multiple input channels still result in only one output, okay!\n",
        "custom_conv2d_2(dummy_images, filters).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWGU0B_l8sDk"
      },
      "source": [
        "# and add output channels\n",
        "dummy_images = np.random.normal(size=(32, 32, 3))\n",
        "filters = np.random.normal(size=(5, 5, 3, 8))\n",
        "\n",
        "# now our output has channels as well\n",
        "custom_conv2d_3(dummy_images, filters).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SFzr6ZE8ve-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}